<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Data Integration | LIS 598 - Data Curation II</title>
  <meta name="description" content="Chapter 5 Data Integration | LIS 598 - Data Curation II" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Data Integration | LIS 598 - Data Curation II" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://opendataliteracy.github.io/LIS598-Sp2020-DC2/data.html" />
  
  
  <meta name="github-repo" content="OpenDataLiteracy/LIS598-Sp2020-DC2" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Data Integration | LIS 598 - Data Curation II" />
  
  
  

<meta name="author" content="Nicholas Weber" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tidy-data.html"/>
<link rel="next" href="data-packaging.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="https://hypothes.is/embed.js" async></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Curation II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Course Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#graduate-school-during-a-pandemic"><i class="fa fa-check"></i><b>1.1</b> Graduate school during a pandemic</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#how-this-class-is-organized"><i class="fa fa-check"></i><b>1.2</b> How this class is organized</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#topic-overview"><i class="fa fa-check"></i><b>1.3</b> Topic Overview</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#grades"><i class="fa fa-check"></i><b>1.4</b> Grades</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#what-to-do-if-you-find-a-mistake-in-this-text"><i class="fa fa-check"></i><b>1.5</b> What to do if you find a mistake in this text</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-curation-ii-introduction.html"><a href="data-curation-ii-introduction.html"><i class="fa fa-check"></i><b>2</b> Data Curation II - Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="data-curation-ii-introduction.html"><a href="data-curation-ii-introduction.html#types-of-knowledge"><i class="fa fa-check"></i><b>2.1</b> Types of Knowledge</a></li>
<li class="chapter" data-level="2.2" data-path="data-curation-ii-introduction.html"><a href="data-curation-ii-introduction.html#working-defintions"><i class="fa fa-check"></i><b>2.2</b> Working Defintions</a></li>
<li class="chapter" data-level="2.3" data-path="data-curation-ii-introduction.html"><a href="data-curation-ii-introduction.html#summary"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html"><i class="fa fa-check"></i><b>3</b> Tables, Trees, and Triples</a><ul>
<li class="chapter" data-level="3.1" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#chapter"><i class="fa fa-check"></i><b>3.1</b> Chapter</a><ul>
<li class="chapter" data-level="3.1.1" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#introduction"><i class="fa fa-check"></i><b>3.1.1</b> Introduction</a></li>
<li class="chapter" data-level="3.1.2" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#levels-of-abstraction"><i class="fa fa-check"></i><b>3.1.2</b> Levels of abstraction</a></li>
<li class="chapter" data-level="3.1.3" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#tables"><i class="fa fa-check"></i><b>3.1.3</b> Tables</a></li>
<li class="chapter" data-level="3.1.4" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#trees"><i class="fa fa-check"></i><b>3.1.4</b> Trees</a></li>
<li class="chapter" data-level="3.1.5" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#data-independence"><i class="fa fa-check"></i><b>3.1.5</b> Data Independence</a></li>
<li class="chapter" data-level="3.1.6" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#trees-and-tables"><i class="fa fa-check"></i><b>3.1.6</b> Trees and Tables</a></li>
<li class="chapter" data-level="3.1.7" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#triples"><i class="fa fa-check"></i><b>3.1.7</b> Triples</a></li>
<li class="chapter" data-level="3.1.8" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#summary-1"><i class="fa fa-check"></i><b>3.1.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#lecture"><i class="fa fa-check"></i><b>3.2</b> Lecture</a></li>
<li class="chapter" data-level="3.3" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#readings"><i class="fa fa-check"></i><b>3.3</b> Readings</a></li>
<li class="chapter" data-level="3.4" data-path="tables-trees-and-triples.html"><a href="tables-trees-and-triples.html#exercise"><i class="fa fa-check"></i><b>3.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tidy-data.html"><a href="tidy-data.html"><i class="fa fa-check"></i><b>4</b> Tidy Data</a><ul>
<li class="chapter" data-level="4.1" data-path="tidy-data.html"><a href="tidy-data.html#chapter-1"><i class="fa fa-check"></i><b>4.1</b> Chapter</a><ul>
<li class="chapter" data-level="4.1.1" data-path="tidy-data.html"><a href="tidy-data.html#tidy-data-principles"><i class="fa fa-check"></i><b>4.1.1</b> Tidy Data Principles</a></li>
<li class="chapter" data-level="4.1.2" data-path="tidy-data.html"><a href="tidy-data.html#pivoting-data"><i class="fa fa-check"></i><b>4.1.2</b> Pivoting data</a></li>
<li class="chapter" data-level="4.1.3" data-path="tidy-data.html"><a href="tidy-data.html#separating-and-gathering"><i class="fa fa-check"></i><b>4.1.3</b> Separating and Gathering</a></li>
<li class="chapter" data-level="4.1.4" data-path="tidy-data.html"><a href="tidy-data.html#tidy-data-in-practice"><i class="fa fa-check"></i><b>4.1.4</b> Tidy Data in Practice</a></li>
<li class="chapter" data-level="4.1.5" data-path="tidy-data.html"><a href="tidy-data.html#extending-tidy-data-beyond-the-traditional-observation"><i class="fa fa-check"></i><b>4.1.5</b> Extending Tidy Data Beyond the Traditional Observation</a></li>
<li class="chapter" data-level="4.1.6" data-path="tidy-data.html"><a href="tidy-data.html#summary-2"><i class="fa fa-check"></i><b>4.1.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="tidy-data.html"><a href="tidy-data.html#lecture-1"><i class="fa fa-check"></i><b>4.2</b> Lecture</a></li>
<li class="chapter" data-level="4.3" data-path="tidy-data.html"><a href="tidy-data.html#readings-1"><i class="fa fa-check"></i><b>4.3</b> Readings</a></li>
<li class="chapter" data-level="4.4" data-path="tidy-data.html"><a href="tidy-data.html#exercise-1"><i class="fa fa-check"></i><b>4.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-integration.html"><a href="data-integration.html"><i class="fa fa-check"></i><b>5</b> Data Integration</a><ul>
<li class="chapter" data-level="5.1" data-path="data-integration.html"><a href="data-integration.html#chapter-2"><i class="fa fa-check"></i><b>5.1</b> Chapter</a><ul>
<li class="chapter" data-level="5.1.1" data-path="data-integration.html"><a href="data-integration.html#integration-as-a-grand-challenge"><i class="fa fa-check"></i><b>5.1.1</b> Integration as a Grand Challenge</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-integration.html"><a href="data-integration.html#enumerating-data-integration-challenges"><i class="fa fa-check"></i><b>5.1.2</b> Enumerating data integration challenges</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-integration.html"><a href="data-integration.html#integration-precursors"><i class="fa fa-check"></i><b>5.1.3</b> Integration Precursors</a></li>
<li class="chapter" data-level="5.1.4" data-path="data-integration.html"><a href="data-integration.html#horizontal-and-vertical-table-integration"><i class="fa fa-check"></i><b>5.1.4</b> Horizontal and Vertical Table Integration</a></li>
<li class="chapter" data-level="5.1.5" data-path="data-integration.html"><a href="data-integration.html#summary-3"><i class="fa fa-check"></i><b>5.1.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-integration.html"><a href="data-integration.html#lecture-2"><i class="fa fa-check"></i><b>5.2</b> Lecture</a></li>
<li class="chapter" data-level="5.3" data-path="data-integration.html"><a href="data-integration.html#readings-2"><i class="fa fa-check"></i><b>5.3</b> Readings</a></li>
<li class="chapter" data-level="5.4" data-path="data-integration.html"><a href="data-integration.html#exercise-2"><i class="fa fa-check"></i><b>5.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-packaging.html"><a href="data-packaging.html"><i class="fa fa-check"></i><b>6</b> Data Packaging</a><ul>
<li class="chapter" data-level="6.1" data-path="data-packaging.html"><a href="data-packaging.html#chapter-3"><i class="fa fa-check"></i><b>6.1</b> Chapter</a><ul>
<li class="chapter" data-level="6.1.1" data-path="data-packaging.html"><a href="data-packaging.html#the-concept-of-packaging-data"><i class="fa fa-check"></i><b>6.1.1</b> The Concept of Packaging Data</a></li>
<li class="chapter" data-level="6.1.2" data-path="data-packaging.html"><a href="data-packaging.html#the-zip-package"><i class="fa fa-check"></i><b>6.1.2</b> The Zip Package</a></li>
<li class="chapter" data-level="6.1.3" data-path="data-packaging.html"><a href="data-packaging.html#data-packages-for-curation"><i class="fa fa-check"></i><b>6.1.3</b> Data Packages for Curation</a></li>
<li class="chapter" data-level="6.1.4" data-path="data-packaging.html"><a href="data-packaging.html#bagit"><i class="fa fa-check"></i><b>6.1.4</b> BagIT</a></li>
<li class="chapter" data-level="6.1.5" data-path="data-packaging.html"><a href="data-packaging.html#why-packages-matter"><i class="fa fa-check"></i><b>6.1.5</b> Why Packages Matter</a></li>
<li class="chapter" data-level="6.1.6" data-path="data-packaging.html"><a href="data-packaging.html#research-object-bagit"><i class="fa fa-check"></i><b>6.1.6</b> Research Object + BagIT</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="data-packaging.html"><a href="data-packaging.html#lecture-3"><i class="fa fa-check"></i><b>6.2</b> Lecture</a></li>
<li class="chapter" data-level="6.3" data-path="data-packaging.html"><a href="data-packaging.html#readings-3"><i class="fa fa-check"></i><b>6.3</b> Readings</a></li>
<li class="chapter" data-level="6.4" data-path="data-packaging.html"><a href="data-packaging.html#exercise-3"><i class="fa fa-check"></i><b>6.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="repository-architectures.html"><a href="repository-architectures.html"><i class="fa fa-check"></i><b>7</b> Repository Architectures</a><ul>
<li class="chapter" data-level="7.1" data-path="repository-architectures.html"><a href="repository-architectures.html#repositories"><i class="fa fa-check"></i><b>7.1</b> Repositories</a></li>
<li class="chapter" data-level="7.2" data-path="repository-architectures.html"><a href="repository-architectures.html#layers-of-a-data-repository"><i class="fa fa-check"></i><b>7.2</b> Layers of a Data Repository</a><ul>
<li class="chapter" data-level="7.2.1" data-path="repository-architectures.html"><a href="repository-architectures.html#data-preservation-oais"><i class="fa fa-check"></i><b>7.2.1</b> Data Preservation + OAIS</a></li>
<li class="chapter" data-level="7.2.2" data-path="repository-architectures.html"><a href="repository-architectures.html#data-repository-frameworks"><i class="fa fa-check"></i><b>7.2.2</b> Data Repository Frameworks</a></li>
<li class="chapter" data-level="7.2.3" data-path="repository-architectures.html"><a href="repository-architectures.html#summary-4"><i class="fa fa-check"></i><b>7.2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="repository-architectures.html"><a href="repository-architectures.html#lecture-4"><i class="fa fa-check"></i><b>7.3</b> Lecture</a></li>
<li class="chapter" data-level="7.4" data-path="repository-architectures.html"><a href="repository-architectures.html#readings-4"><i class="fa fa-check"></i><b>7.4</b> Readings</a></li>
<li class="chapter" data-level="7.5" data-path="repository-architectures.html"><a href="repository-architectures.html#exercise-4"><i class="fa fa-check"></i><b>7.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html"><i class="fa fa-check"></i><b>8</b> Data Acquisition, Search, and Discovery</a><ul>
<li class="chapter" data-level="8.1" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#chapter-4"><i class="fa fa-check"></i><b>8.1</b> Chapter</a><ul>
<li class="chapter" data-level="8.1.1" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#a-brief-review-of-information-searching"><i class="fa fa-check"></i><b>8.1.1</b> A Brief Review of Information Searching</a></li>
<li class="chapter" data-level="8.1.2" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#data-discovery-challenges---by-example"><i class="fa fa-check"></i><b>8.1.2</b> Data Discovery Challenges - By Example</a></li>
<li class="chapter" data-level="8.1.3" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#open-data-discovery"><i class="fa fa-check"></i><b>8.1.3</b> Open Data Discovery</a></li>
<li class="chapter" data-level="8.1.4" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#summary-5"><i class="fa fa-check"></i><b>8.1.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#lecture-5"><i class="fa fa-check"></i><b>8.2</b> Lecture</a></li>
<li class="chapter" data-level="8.3" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#exercise-5"><i class="fa fa-check"></i><b>8.3</b> Exercise</a><ul>
<li class="chapter" data-level="8.3.1" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#simple-rest-example"><i class="fa fa-check"></i><b>8.3.1</b> Simple REST Example</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#json-parser-with-api"><i class="fa fa-check"></i><b>8.4</b> JSON Parser with API</a><ul>
<li class="chapter" data-level="8.4.1" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#programmatic-access-to-apis"><i class="fa fa-check"></i><b>8.4.1</b> Programmatic Access to APIs</a></li>
<li class="chapter" data-level="8.4.2" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#final-tip"><i class="fa fa-check"></i><b>8.4.2</b> Final Tip</a></li>
<li class="chapter" data-level="8.4.3" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#additional-apis-i-recommend-for-practice"><i class="fa fa-check"></i><b>8.4.3</b> Additional APIs I Recommend for Practice</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="data-acquisition-search-and-discovery.html"><a href="data-acquisition-search-and-discovery.html#reading"><i class="fa fa-check"></i><b>8.5</b> Reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html"><i class="fa fa-check"></i><b>9</b> Metadata Application Profiles</a><ul>
<li class="chapter" data-level="9.0.1" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#introduction-1"><i class="fa fa-check"></i><b>9.0.1</b> Introduction</a></li>
<li class="chapter" data-level="9.0.2" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#semantics-and-syntax-of-metadata"><i class="fa fa-check"></i><b>9.0.2</b> Semantics and Syntax of Metadata</a></li>
<li class="chapter" data-level="9.0.3" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#tidy-metadata"><i class="fa fa-check"></i><b>9.0.3</b> Tidy Metadata</a></li>
<li class="chapter" data-level="9.0.4" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#using-tidy-metadata-principles-for-maps"><i class="fa fa-check"></i><b>9.0.4</b> Using Tidy Metadata Principles for MAPs</a></li>
<li class="chapter" data-level="9.0.5" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#tidy-metadata-best-practices"><i class="fa fa-check"></i><b>9.0.5</b> Tidy Metadata Best Practices</a></li>
<li class="chapter" data-level="9.0.6" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#principle-11-relationships"><i class="fa fa-check"></i><b>9.0.6</b> Principle: 1:1 Relationships</a></li>
<li class="chapter" data-level="9.1" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#lecture-6"><i class="fa fa-check"></i><b>9.1</b> Lecture</a></li>
<li class="chapter" data-level="9.2" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#exercise-6"><i class="fa fa-check"></i><b>9.2</b> Exercise</a></li>
<li class="chapter" data-level="9.3" data-path="metadata-application-profiles.html"><a href="metadata-application-profiles.html#reading-1"><i class="fa fa-check"></i><b>9.3</b> Reading</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="linked-data.html"><a href="linked-data.html"><i class="fa fa-check"></i><b>10</b> Linked Data</a><ul>
<li class="chapter" data-level="10.0.1" data-path="linked-data.html"><a href="linked-data.html#the-early-web"><i class="fa fa-check"></i><b>10.0.1</b> The Early Web</a></li>
<li class="chapter" data-level="10.0.2" data-path="linked-data.html"><a href="linked-data.html#the-promise-and-failure-of-the-semantic-web"><i class="fa fa-check"></i><b>10.0.2</b> The promise and failure of the Semantic Web</a></li>
<li class="chapter" data-level="10.0.3" data-path="linked-data.html"><a href="linked-data.html#linked-data-1"><i class="fa fa-check"></i><b>10.0.3</b> Linked Data</a></li>
<li class="chapter" data-level="10.0.4" data-path="linked-data.html"><a href="linked-data.html#json-ld"><i class="fa fa-check"></i><b>10.0.4</b> JSON-LD</a></li>
<li class="chapter" data-level="10.0.5" data-path="linked-data.html"><a href="linked-data.html#practical-json-ld"><i class="fa fa-check"></i><b>10.0.5</b> Practical JSON-LD</a></li>
<li class="chapter" data-level="10.0.6" data-path="linked-data.html"><a href="linked-data.html#linked-data-for-curation"><i class="fa fa-check"></i><b>10.0.6</b> Linked Data for Curation</a></li>
<li class="chapter" data-level="10.1" data-path="linked-data.html"><a href="linked-data.html#lecture-7"><i class="fa fa-check"></i><b>10.1</b> Lecture</a></li>
<li class="chapter" data-level="10.2" data-path="linked-data.html"><a href="linked-data.html#reading-2"><i class="fa fa-check"></i><b>10.2</b> Reading</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="emerging-topics.html"><a href="emerging-topics.html"><i class="fa fa-check"></i><b>11</b> Emerging Topics</a><ul>
<li class="chapter" data-level="11.1" data-path="emerging-topics.html"><a href="emerging-topics.html#chapter-5"><i class="fa fa-check"></i><b>11.1</b> Chapter</a></li>
<li class="chapter" data-level="11.2" data-path="emerging-topics.html"><a href="emerging-topics.html#lecture-8"><i class="fa fa-check"></i><b>11.2</b> Lecture</a></li>
<li class="chapter" data-level="11.3" data-path="emerging-topics.html"><a href="emerging-topics.html#exercise-7"><i class="fa fa-check"></i><b>11.3</b> Exercise</a></li>
<li class="chapter" data-level="11.4" data-path="emerging-topics.html"><a href="emerging-topics.html#reading-3"><i class="fa fa-check"></i><b>11.4</b> Reading</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="protocol-assignment.html"><a href="protocol-assignment.html"><i class="fa fa-check"></i><b>12</b> Protocol Assignment</a><ul>
<li class="chapter" data-level="12.1" data-path="protocol-assignment.html"><a href="protocol-assignment.html#overview-requirements"><i class="fa fa-check"></i><b>12.1</b> Overview &amp; Requirements</a></li>
<li class="chapter" data-level="12.2" data-path="protocol-assignment.html"><a href="protocol-assignment.html#pre-protocol-assignment-data-pitch"><i class="fa fa-check"></i><b>12.2</b> Pre-Protocol Assignment: Data Pitch</a></li>
<li class="chapter" data-level="12.3" data-path="protocol-assignment.html"><a href="protocol-assignment.html#assignment-0-project-definition-scope-and-audience"><i class="fa fa-check"></i><b>12.3</b> Assignment 0: Project definition, scope, and audience</a></li>
<li class="chapter" data-level="12.4" data-path="protocol-assignment.html"><a href="protocol-assignment.html#assignment-1-user-stories-use-cases"><i class="fa fa-check"></i><b>12.4</b> Assignment 1: User Stories + Use Cases</a><ul>
<li class="chapter" data-level="12.4.1" data-path="protocol-assignment.html"><a href="protocol-assignment.html#user-stories"><i class="fa fa-check"></i><b>12.4.1</b> User Stories</a></li>
<li class="chapter" data-level="12.4.2" data-path="protocol-assignment.html"><a href="protocol-assignment.html#use-cases-best-practices"><i class="fa fa-check"></i><b>12.4.2</b> Use Cases (Best Practices)</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="protocol-assignment.html"><a href="protocol-assignment.html#assignment-2-data-collection-policies"><i class="fa fa-check"></i><b>12.5</b> Assignment 2: Data Collection Policies</a></li>
<li class="chapter" data-level="12.6" data-path="protocol-assignment.html"><a href="protocol-assignment.html#assignment-3-data-transformations-and-quality-criteria"><i class="fa fa-check"></i><b>12.6</b> Assignment 3: Data Transformations and Quality Criteria</a></li>
<li class="chapter" data-level="12.7" data-path="protocol-assignment.html"><a href="protocol-assignment.html#assignment-4-data-licensing"><i class="fa fa-check"></i><b>12.7</b> Assignment 4: Data Licensing</a></li>
<li class="chapter" data-level="12.8" data-path="protocol-assignment.html"><a href="protocol-assignment.html#assignment-5-metadata-application-profiles"><i class="fa fa-check"></i><b>12.8</b> Assignment 5: Metadata Application Profiles</a></li>
<li class="chapter" data-level="12.9" data-path="protocol-assignment.html"><a href="protocol-assignment.html#assignment-optional-repository-architectures"><i class="fa fa-check"></i><b>12.9</b> Assignment OPTIONAL: Repository Architectures</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>13</b> Appendix</a><ul>
<li class="chapter" data-level="13.1" data-path="appendix.html"><a href="appendix.html#hypothes.is"><i class="fa fa-check"></i><b>13.1</b> Hypothes.is</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">LIS 598 - Data Curation II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-integration" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Data Integration</h1>
<div id="chapter-2" class="section level2">
<h2><span class="header-section-number">5.1</span> Chapter</h2>
<p>The next four weeks of our class will focus on ‘grand challenges’ in data curation. A <a href="https://en.wikipedia.org/wiki/Grand_Challenges">grand challenge</a> in this context is a problem that requires sustained research and development activities through collective action. Data integration, packaging, discovery, and meaningful descriptive documentation (metadata) are longstanding grand challenges that are approached through a community of practitioners and researchers in curation. This chapter focuses on data integration as it operates at the logical level of tables, and data that feed into user interfaces.</p>
<div id="integration-as-a-grand-challenge" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Integration as a Grand Challenge</h3>
<p>In the popular imagination, much of curation work is positioned as the activities necessary to prepare data for meaningful analysis and reuse. For example, when data scientists describe curation work they often say something to the effect of “95% of data science is about wrangling / cleaning”</p>
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">
Convert back and forth from JSON to Python dictionaries. <a href="https://t.co/AOFXuKWhm3">pic.twitter.com/AOFXuKWhm3</a>
</p>
— Vicki Boykis (<span class="citation">(<span class="citeproc-not-found" data-reference-id="vboykis"><strong>???</strong></span>)</span>) <a href="https://twitter.com/vboykis/status/1116862862755016704?ref_src=twsrc%5Etfw">April 13, 2019</a>
</blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>If there are only two things I am trying to actively argue against in this class it is this:</p>
<ul>
<li>Curation is not <em>just</em> cleaning or wrangling data. It includes the attendant practices of making data contextually meaningful. This includes a good deal of cleaning or wrangling, but is much broader in scope than simply preparing data for analysis.</li>
<li>Metadata is not just “data about data”. It is a complex and important knowledge organization activity that impacts nearly every aspect of data use. Every time someone says “metadata is just data about data” a tautology angel gets its wings.</li>
</ul>
<p>In future weeks we will discuss practical ways to approach metadata and documentation that are inline with curation as an activity that goes beyond simply preparing data for analysis. This week however we are focused on conceptualizing and approaching the topic of data integration. The combining of datasets is a grand challenge for curation in part because of our expectations for how seemingly obvious this activity <em>should</em> be. Take a moment to consider this at a high level of abstraction: One of the spillover effects of increased openness in government, scientific, and private sector data practices is the availability of more and more structured data. The ability to combine and meaningfully incorporate different information, based on these structures, should be possible. For example:</p>
<ul>
<li>All municipalities have a fire department.</li>
<li>All municipal fire departments have a jurisdictional mandate to proactively investigate fire code compliance.</li>
<li>It follows, logically, that we should be able to use openly published structured data to look across jurisdictions and understand fire code compliance.</li>
</ul>
<p>But, in practice this proves to be incredibly difficult. Each jurisdiction has a slightly different fire code, and each municipal fire department records their investigation of compliance in appreciably different ways. So when we approach a question like “fire code compliance” we have to not just clean data in order for it be combined, but think conceptually about the structural differences in datasets and how they might be integrated with one another.</p>
</div>
<div id="enumerating-data-integration-challenges" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Enumerating data integration challenges</h3>
<p>So, if structured data integration is intuitive conceptually, but in practice the ability to combine one or more data sources is incredibly difficult, then we should be able to generalize some of the problems that are encountered in this activity. Difficulties in data integration break down into, at least, the following:</p>
<ol style="list-style-type: decimal">
<li><strong>Content Semantics:</strong> Different sectors, jurisdictions, or even domains of inquiry may refer to the same concept differently. In data tidying we discussed ways that data values and structures can be made consistent, but we didn’t discuss the ways in which different tables might be combined when they represent the same concept differently.</li>
<li><strong>Data Structures or Encodings:</strong> Even if the same concepts are present in a dataset, the data may be practically arranged or encoded in different ways. This may be as simple as variables being listed in a different order, but it may also mean that one dataset is published in <code>CSV</code> another in <code>JSON</code> and yet another in an <code>SQL</code> table export.</li>
<li><strong>Data Granularity:</strong> The same concept may be present in a dataset, but it may have finer or coarser levels of granularity (e.g. One dataset may have monthly aggregates and another contains daily aggregates).</li>
</ol>
<p>The curation tradeoff that we’ve discussed throughout both DC 1 and DC 2 in terms of “expressivity and tractability” is again rearing its head. In deciding how any one difficulty should be overcome we have to balance a need for retaining conceptual representations that are accurate and meaningful. In data integration, we have to be careful not go overboard in retaining an accurate representation of the same concept such that it fails to be meaningfully combined with another dataset.</p>
<p>Data Integration, as you might have inferred, is always a downstream curation activity. But, understanding challenges in data integration can also help with decisions that happen upstream in providing recommendations for how data can be initially recorded and documented such that it will be <em>amenable</em> to future integration.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
</div>
<div id="integration-precursors" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Integration Precursors</h3>
<p>To overcome difficulties in combining different data tables we can engage with curation activities that I think of as ‘integration precursors’ - ways to conceptualize and investigate differences in two datasets before we begin restructuring, normalization, or cleaning. These integration precursors are related to 1. Modeling; 2. Observational depth; and, 3. Variable Homogeneity.</p>
<div id="modeling-table-content" class="section level4">
<h4><span class="header-section-number">5.1.3.1</span> Modeling Table Content</h4>
<p>The first activity in data integration is to informally or formally model the structure of a data table. In DC 1 we created data dictionaries which were focused on providing users of data a quick and precise overview of their contents. Data dictionaries are also a method for informally modeling the content of a dataset so that we, as curators, can make informed decisions about restructuring and cleaning.</p>
<p>Here is an example of two data dictionaries for the same conceptual information: 311 service requests to the city of <a href="https://data.cityofchicago.org/Service-Requests/311-Service-Requests/v6vf-nfxy">Chicago, IL</a> and <a href="https://data.austintexas.gov/City-Government/311-Unified-Data-Test-Site-2019/i26j-ai4z">Austin, TX</a>. Intuitively, we would expect that data from these two cities are similar enough in content that they can be meaningfully combined.</p>
<p>Before even before looking at the content of either data table we can assume there will be:</p>
<ol style="list-style-type: decimal">
<li>A date</li>
<li>A report of some service outage or complaint</li>
<li>A location of the report or complaint, and</li>
<li>The responsible city service that should respond.</li>
</ol>
<p>The reality is much messier.</p>
<div class="figure">
<img src="Images/dataintegration-model.png" alt="Data Dictionaries from Chicago and Austin 311 Data" />
<p class="caption">Data Dictionaries from Chicago and Austin 311 Data</p>
</div>
<p>Even though these two cities record the same information about the same concept using the same data infrastructure (each city publishes data using a Socrata-based data repository) there are appreciable differences and challenges in integrating these two datasets. The annotations above point out some of these slight but appreciable differences:</p>
<ul>
<li><p>Granularity - We can see that the Chicago dataset contains a variable <code>SR_Status</code> that includes information about whether or not the request is open, as well as whether or not the request is a duplicate. The Austin dataset contains a similar variable <code>Status</code> but instead of also recording a duplicate here, there is a second variable <code>Duplicate</code> that contains this information. That is, the Austin dataset is more granular. If duplicate information were important to retain in our integrated dataset we would need to determine a way to tidy these variables or values.</p></li>
<li><p>Semantics - Both datasets include information about the most recent update (response) to the request, but these are variables are labeled in slightly different ways - <code>Last_Update_Date</code> and <code>Last_Modified_Date</code> … This should be a simple to tidy by renaming the data variable (but as we will see, this proves to be more more challenging than just renaming the variable).</p></li>
<li><p>Structure - Both datasets also include location information about the report. However, there is both different granularity as well as a different ordering of these variables. To tidy this location information, we would need to determine which variables to retain and which to discard.</p></li>
</ul>
<p>The process of modeling our data tables before integration facilitates making accurate decisions, but also enables us to record those decisions and communicate them to end-users. A data dictionary, or a loose description of the contents of both tables, is often our first step in deciding which data cleaning activities we need to undertake for integrating data.</p>
</div>
<div id="determine-the-observation-depth" class="section level4">
<h4><span class="header-section-number">5.1.3.2</span> Determine the Observation Depth</h4>
<p>In integrating two data tables there will likely be a difference in granularity of values. That is, even if the same variable is present in both datasets this does not necessarily mean that the same unit of measurement is used between the two data tables.</p>
<p>As curators, value granularity prompts a decision about what specificity is necessary to retain or discard for an integrated table.</p>
<p>A simple example will make this clear. Imagine we have three tables<code>A</code>, <code>B</code>, and <code>C</code>. Each table contains the same variable <code>X</code>, but the values for <code>X</code> in each table have a different observational depth. In comparing the values for this variable we might observe different units of measurement.</p>
<table>
<thead>
<tr class="header">
<th>A-X</th>
<th>B-X</th>
<th>C-X</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>1.1</td>
</tr>
<tr class="even">
<td>1</td>
<td>2</td>
<td>4.7</td>
</tr>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>4.4</td>
</tr>
<tr class="even">
<td>1</td>
<td>2</td>
<td>3.0</td>
</tr>
</tbody>
</table>
<p>(Keep in mind - A, B and C represent the three different tables, and X represents the same variable found in all three tables)</p>
<p>This example looks simple at face value, but will require an important decision for integration. Tables <code>A</code> and <code>B</code> both represent observational values of <code>X</code> as integers (whole numbers that are zero, negative, or positive). Table <code>C</code> represents the observational values of <code>X</code> as an irrational number (with a decimal place).</p>
<p>Once we recognize this difference, our decision is simple - we can either convert the values in <code>A</code> and <code>B</code> to be irrational (1.0, 2.0, etc) or we can round the values in <code>C</code> to create integers.</p>
<p>Regardless of our decision it is important to note that we are not just changing the values, but we are also changing their <code>encoding</code> - that is whether they represent integers or irrational numbers. (And we would need to document this change in our documentation).</p>
<p>Let’s look at differences in observational depth from two variables in the 311 data described above.</p>
<table>
<thead>
<tr class="header">
<th>Created Date</th>
<th>Created Date</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:58:34 AM</td>
</tr>
<tr class="even">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:57:21 AM</td>
</tr>
<tr class="odd">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:54:04 AM</td>
</tr>
<tr class="even">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:52:39 AM</td>
</tr>
<tr class="odd">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:52:17 AM</td>
</tr>
<tr class="even">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:46:53 AM</td>
</tr>
<tr class="odd">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:46:29 AM</td>
</tr>
<tr class="even">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:43:44 AM</td>
</tr>
<tr class="odd">
<td>4/20/20 10:14</td>
<td>2020 Apr 20 10:43:35 AM</td>
</tr>
<tr class="even">
<td>4/20/20 10:13</td>
<td>2020 Apr 20 10:43:29 AM</td>
</tr>
<tr class="odd">
<td>4/20/20 10:13</td>
<td>2020 Apr 20 10:41:31 AM</td>
</tr>
<tr class="even">
<td>4/20/20 10:13</td>
<td>2020 Apr 20 10:40:38 AM</td>
</tr>
<tr class="odd">
<td>4/20/20 10:13</td>
<td>2020 Apr 20 10:40:28 AM</td>
</tr>
</tbody>
</table>
<p>Chicago represents time of a 311 report following a <code>MM-DD-YY HH:MM</code> form, while Austin represents this same information with <code>YYYY-MMM-DD HH:MM:SS 12HRM</code></p>
<p>The observational depth is greater (has more granularity) in the Austin table. But, we also have some untidy representations of <code>date</code> in both datasets.</p>
<p>If we want to integrate these two tables then we have to decide</p>
<ol style="list-style-type: decimal">
<li>How to normalize the values; and,</li>
<li>Which depth of granularity to retain.</li>
</ol>
<p>Regardless of how we decide to normalize this data, what we have to try to retain is a reliable reporting of the date such that the two sets of observations are homogenous. For example, the Chicago data doesn’t include seconds for a 311 request. So, we can either add these seconds as <code>00</code> values in the Chicago table, or we can remove the seconds from the Austin table In either decision, we are changing the depth of granularity in our integrated table. (Note, we also need to transform the hours so that they either represent a 24 hour cycle, or are marked by a 12HR marking such as <code>AM</code> or <code>PM</code>).</p>
</div>
<div id="determine-variable-homogeneity" class="section level4">
<h4><span class="header-section-number">5.1.3.3</span> Determine Variable Homogeneity</h4>
<p>The last integration precursor that we’ll discuss has to do with the homogeneity of a variable. In modeling two or more tables for potential integration we will seek to define and describe which variables are present, but we’ve not yet identified whether or not two variables can be reliably combined. To make this decision we need to first determine the goals of the integration. Some general criteria to consider when thinkng about the goals of integration are as follows:</p>
<ul>
<li>Analysis and Computation - If we are optimizing data integration for easing analysis then we want high amount of homogeneity in the variables we will combine.</li>
<li>Synthesis - If we are optimizing for a more general purpose, such as the ability to synthesize results from two different datasets, then we can likely afford to combine variables that may have less homogeneity</li>
<li>Statistical Significance - If we expect to create statistical summaries that require significant results (that is we will make some decision or generalization based on our statistical analysis) then it is of the utmost importance that the combined variables have high homogeneity. But, if all that we require is a rough sense of when or where an observation occurs then low homogeneity is acceptable.</li>
</ul>
<p>An example of variable homogeneity will help make these points clear. The Austin and Chicago tables each contain a variable that roughly corresponds with the “type” of 311 request or report being made. In the Austin table this information is more granularly reported - there is code that is used internally <code>SR_Type_Code</code>, and a <code>Description</code> variable that provides a plain text explanation of the code. In the Chicago table there is simply a variable called <code>SR_Type</code>. If we pay attention closely to the values in these two tables we can determine that the <code>Description</code> and <code>SR_Type</code> are homogenous. That is, the Austin table and the Chicago table have similar information but use slightly different semantic values to control the variable.</p>
<table>
<thead>
<tr class="header">
<th>Description</th>
<th>SR_Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tree Issue ROW</td>
<td>Aircraft Noise Complaint</td>
</tr>
<tr class="even">
<td>ARR Missed Recycling</td>
<td>Vacant/Abandoned Building Complaint</td>
</tr>
<tr class="odd">
<td>Street Light Issue- Address</td>
<td>Tree Removal Request</td>
</tr>
<tr class="even">
<td>Found Animal Report - Keep</td>
<td>Sign Repair Request - All Other Signs</td>
</tr>
<tr class="odd">
<td>Dangerous/Vicious Dog Investigation</td>
<td>Rodent Baiting/Rat Complaint</td>
</tr>
<tr class="even">
<td>Traffic Signal - Maintenance</td>
<td>Rodent Baiting/Rat Complaint</td>
</tr>
<tr class="odd">
<td>ARR Dead Animal Collection</td>
<td>Aircraft Noise Complaint</td>
</tr>
<tr class="even">
<td>ARR Dead Animal Collection</td>
<td>Rodent Baiting/Rat Complaint</td>
</tr>
<tr class="odd">
<td>ARR Missed Yard Trimmings/Compost</td>
<td>Rodent Baiting/Rat Complaint</td>
</tr>
<tr class="even">
<td>ARR Missed Yard Trimmings/Compost</td>
<td>Fly Dumping Complaint</td>
</tr>
<tr class="odd">
<td>Animal Control - Assistance Request</td>
<td>Tree Debris Clean-Up Request</td>
</tr>
<tr class="even">
<td>Street Light Issue- Address</td>
<td>Aircraft Noise Complaint</td>
</tr>
<tr class="odd">
<td>Street Light Issue- Address</td>
<td>Aircraft Noise Complaint</td>
</tr>
<tr class="even">
<td>Street Light Issue- Address</td>
<td>Rodent Baiting/Rat Complaint</td>
</tr>
</tbody>
</table>
<p>Integrating these two variables in the same table seems possible, but we have a decision to make: We can either combine the two variables and leave the semantic value with low homogeneity, or we can create something like a controlled vocabulary for describing the type of 311 request being made and then normalize the data so that each value is transformed to be compliant with our vocabulary. For example, <code>Street Light Issue - Address</code> in the Austin table, and <code>Sign Repair Request</code> in the Chicago table both have to do with a report being made about public signage. We could create a broad category like <code>Public Signage</code> and then transform (that is, change the values) accordingly. But, we have only determined this step is possible by comparing the two variables directly.</p>
<p>When we determine there is a variable homogeneity that matches our intended integration goal we can then take a curation action. But, it is only through modeling, exploring observational depth, and investigating variable homogeneity that we can arrive at any one proper curation decision. It’s worth noting that the first two precursors - modeling and observational depth - don’t require us to necessarily have a goal in mind. We can start to engage in these activities before we quite know exactly what, or why we are going to integrate two tables. It is at the final step, variable homogeneity, that we start to formalize our goals and optimize our decisions as a result.</p>
</div>
</div>
<div id="horizontal-and-vertical-table-integration" class="section level3">
<h3><span class="header-section-number">5.1.4</span> Horizontal and Vertical Table Integration</h3>
<p>Thus far we’ve described precursors to making decisions and preparing data for integration. Once we’ve taken these steps we’re left with the practical task of combining the two tables. Generally, there are two types of table combinations that can be made: Horizontal and Vertical Integration.</p>
<div id="horizontal-data-integration" class="section level4">
<h4><span class="header-section-number">5.1.4.1</span> Horizontal data integration</h4>
<p>Horizontal data integration is necessary when we have the same set of observations, but multiple variables <em>scattered</em> across two tables. By performing a horizontal data integration we make a table <em>wider</em> by adding new variables for each observation. If you have any experience with databases this is also referred to as a <strong>join</strong>. To horizontally integrate data we perform <code>left_joins</code> or <code>right_joins</code>.</p>
<p>To accurately perform a horizontal data integration manually - that is copying and pasting between two datasets - it is necessary to make sure that each dataset has a shared variable (you can copy one variable between the two datasets if they do not already share one). When we copy and paste one table into another, we can then simply align the two shared variables to complete the integration.</p>
<p>I am also going to show you how how to perform a horizontal data integration using <code>R</code> … You do not have to follow these steps unless you are interested. To follow along you should download and install <a href="https://rstudio.com/products/rstudio/download/">RStudio</a> (select the RStudio Desktop free installation). These example comes from friends running the <a href="https://github.com/LOST-STATS">Lost Stats</a> project.</p>
<pre><code># Install dplyr - a package in the tidyverse for restructuring data
install.packages(&#39;dplyr&#39;)

# Load the library by calling it in your terminal.
library(dplyr)

# The data we will use contains information on GDP in local currency
GDP2018 &lt;- data.frame(Country = c(&quot;UK&quot;, &quot;USA&quot;, &quot;France&quot;),
                  Currency = c(&quot;Pound&quot;, &quot;Dollar&quot;, &quot;Euro&quot;),
                  GDPTrillions = c(2.1, 20.58, 2.78))

#To view the data we have just created follow the next step
View(GDP2018)

# Now we will create a second data set that contains dollar exchange rates
DollarValue2018 &lt;- data.frame(Currency = c(&quot;Euro&quot;, &quot;Pound&quot;, &quot;Yen&quot;, &quot;Dollar&quot;),
                              InDollars = c(1.104, 1.256, .00926, 1))</code></pre>
<p>In the initial steps above we have created two data tables and assigned these tables to the name <code>GDP2018</code> and <code>DollarValue2018</code>.</p>
<p>To horizontally integrate these two tables we want to <strong>join</strong> or combine <code>GDP2018</code> and <code>DollarValue2018</code>.</p>
<p>Use <code>help(join)</code> to see the types of joins that we can make in R.</p>
<p>To complete our horizontal data integration we simply do the following:</p>
<pre><code>GDPandExchange &lt;- left_join(GDP2018, DollarValue2018)

#We have now horizontally integrated our two datasets. To view this integrated dataset do the following
View(GDPandExchange)</code></pre>
<p>One helpful note about the package <code>dplyr</code> that will clarify some of the magic that just happened… the <code>join</code> function will automatically detect that the <code>Currency</code> variable is shared in both data tables. In recognizing this shared variable <code>dplyr</code> will use this, automatically, as the place to perform the left join. And helpfully, when <code>dplyr</code> detects this similarity, it simply retains just one example of the <code>Currency</code> variables and its values. Voila - a single tidy data table through horizontal data integration !</p>
</div>
<div id="vertical-data-integration" class="section level4">
<h4><span class="header-section-number">5.1.4.2</span> Vertical data integration</h4>
<p>Vertical data integration, which is much more common in curation, is when we have two tables with the same variables, but different observations. To perform a vertical integration we simply add new observations to one of our existing datasets. This makes our integrated data table <em>longer</em> because it contains more observations.</p>
<p>In <code>R</code> we first will subset a native data table (one that is included as an example) and then recombine it to see how vertical integration works in practice.</p>
<pre><code># Load the dplyr library so we can use its magic 
library(dplyr)

# Load in mtcars data - a dataset that is native to R
data(mtcars)

# Take a look at the dataset and see what we will be first splitting and then recombining
View(mtcars)

# Split the dataset in two, so we can combine these back together
mtcars1 &lt;- mtcars[1:10,]
mtcars2 &lt;- mtcars[11:32,]

#Our comptuer is now holding the two tables in its memory - mtcars 1 and mtcars2. If you want to check this try 

View(mtcars1)

# Use bind_rows to vertically combine the data tables 
mtcarswhole &lt;- bind_rows(mtcars1, mtcars2)

# The bind_rows command is simply concatenating or combing the two datsets one on top of the other.
# Now check to see the horizontally combined data tables
View(mtcarswhole)</code></pre>
<p>These are the two most common integration tasks we will perform - integrating datasets with complimentary variables, and integrating datasets with new observations.</p>
<p>The hard part about data integration, as should be obvious by now, is in evaluating and preparing data to be combined. Once we have thoroughly completed each of the different integration precursors our task for actually integrating tables is relatively simple.</p>
</div>
</div>
<div id="summary-3" class="section level3">
<h3><span class="header-section-number">5.1.5</span> Summary</h3>
<p>In this introduction to grand challenges in data curation we explored ways to prepare for and execute data integration at the table level. We first articulated a set of things that makes all data integration challenging:</p>
<ol style="list-style-type: decimal">
<li>Differences in semantic content</li>
<li>Differences in data structure and encoding</li>
<li>Differences in data granularity</li>
</ol>
<p>To overcome these challenges I proposed a set of <code>integration precursors</code> that included:</p>
<ol style="list-style-type: decimal">
<li>Modeling data content</li>
<li>Determining Observation Depth</li>
<li>Determining Variable Homogeneity (its at this stage we start to formalize our integration goals)</li>
</ol>
<p>Once these tasks were complete we looked at practical ways to combine two tables, including horizontal and vertical integration. We also were introduced to the magic of <code>dplyr</code> in performing simple data integrations.</p>
</div>
</div>
<div id="lecture-2" class="section level2">
<h2><span class="header-section-number">5.2</span> Lecture</h2>
<iframe width="853" height="476" frameborder="0" scrolling="no" src="https://screencast-o-matic.com/embed?sc=cYf3oHAIEB&amp;v=6&amp;ff=1&amp;title=0&amp;controls=1" allowfullscreen="true">
</iframe>
</div>
<div id="readings-2" class="section level2">
<h2><span class="header-section-number">5.3</span> Readings</h2>
<p>Data integration is a topic that can be incredibly complex, and much of the published literature fails to make this an approachable or even realistic read for a course like DC II. So, you get somewhat of a pass on readings this week.</p>
<p>A very helpful overview of the state of current integration challenges for the open web of data:</p>
<ul>
<li>Stonebraker, M., &amp; Ilyas, I. F. (2018). Data Integration: The Current Status and the Way Forward. IEEE Data Eng. Bull., 41(2), 3-9. <a href="https://cs.uwaterloo.ca/~ilyas/papers/StonebrakerIEEE2018.pdf">PDF</a></li>
</ul>
<p>Please read this blog post for discussion (if you chose) on the Canvas forum:</p>
<ul>
<li>Whong, Chris (2020) “Taming the MTA’s Unruly Turnstile Data” <a href="https://medium.com/qri-io/taming-the-mtas-unruly-turnstile-data-c945f5f96ba0">Medium</a></li>
</ul>
<p>Let me also make a plug for the Wikipedia article on <a href="https://en.wikipedia.org/wiki/Data_integration">data integration</a> - this is a phenomenal overview that should compliment my writing above.</p>
<p>If you are interested in the history of this topic from the perspective of databases I also highly recommend the following:</p>
<ul>
<li>Halevy, A., Rajaraman, A., &amp; Ordille, J. (2006, September). Data integration: The teenage years. In Proceedings of the 32nd international conference on Very large data bases (pp. 9-16). <a href="https://www.cin.ufpe.br/~if696/referencias/integracao/_Data_Integration-The_Teenage_Years.pdf">PDF</a></li>
</ul>
<p>For a bit of historical background, Ch 1 of this book (pages 1-13) provides an excellent overview of how data were originally made compliant with web standards:</p>
<ul>
<li>Abiteboul, S., Buneman, P., &amp; Suciu, D. (2000). Data on the Web: from relations to semistructured data and XML. Morgan Kaufmann. <a href="https://homepages.dcc.ufmg.br/~laender/material/Data-on-the-Web-Skeleton.pdf">PDF</a></li>
</ul>
</div>
<div id="exercise-2" class="section level2">
<h2><span class="header-section-number">5.4</span> Exercise</h2>
<p>The exercise this week comes from an interesting analysis of New York City 311 data by <a href="https://t.co/J7X3FMUvQc?amp=1">Chris Whong</a>. What he observes is a 1000% increase in “Consumer Complaint” 311 requests since the first recorded case of Covid-19 infection in NYC. This is not without some important external conditions - After this recorded infection there was a more concerted effort by NYC residents to stockpile supplies. Having heard numerous informal complaints of price-gouging the city recommended that consumers report businesses using a 311 hotline.</p>
<p>A simple graph makes this more compelling than the narrative description - we see a huge spike in complaints beginning March 1st.
<img src="https://pbs.twimg.com/media/ETapolDX0AAt9Ye?format=png&amp;name=900x900" /></p>
<p>As savvy data curators, we might ask whether or not this trend holds across cities throughout the USA. And at its core, this is a data integration challenge. If we can find other city’s 311 data we should be able to reliably compare rates of 311 complaints over time. The challenge will be finding data that has the same kinds of variables, and normalizing values to have a one to one comparison between cities.</p>
<p>Lucky for us, there is an existing repository of <a href="https://andrew-friedman.github.io/jkan/datasets/">311 city data</a>.</p>
<p>Your exercise this week is to choose two cities from this repository and attempt to integrate a subset of their data. This will be challenging.</p>
<p><strong>Here are some helpful pointers:</strong></p>
<ul>
<li>Choose cities that have “up-to-date” data (marked by “current” in the title)</li>
<li>Subset this data so that it only includes 311 complains from March 1, 2020 forward. You can often subset data in a repository by choosing to view and filter the data first. Here is an example from <a href="https://data.cityofchicago.org/Service-Requests/311-Service-Requests/v6vf-nfxy/data">Chicago’s open data portal</a> (note just select filter in this interface)</li>
<li>Once you have subsetted the tables for your two cities, try to eliminate any unnecessary variables from your dataset. That is - we don’t need all of the information about the data - we only need a record of, for example, the complaint and the date.</li>
</ul>
<p><strong>What to turn in:</strong></p>
<ul>
<li>Provide us a table of your data from two cities (a Google Sheet or Excel document is fine). If you are able to integrate the data, provide just one sheet. If you cannot - give us two separate sheets. Note - this will be challenging to do. If you spend an hour trying to integrate the two datasets and up hating me (and this class) that is completely acceptable, but make an attempt and then follow the next step.</li>
<li>Provide an explanation (~1 paragraph) of which cities you selected, what you tried to integrate the data, and why this was or was not challenging.</li>
<li>You do not need to create a graph or any form of analysis - but if you do it would be very interesting to see your results!</li>
</ul>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>A small plug here for our opening chapter - when I described a curators need to “infrastructurally imagine” how data will be used and reused within a broader information system, upstream curation activities that forecast data integration challenges are very much what I meant.<a href="data-integration.html#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tidy-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data-packaging.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
